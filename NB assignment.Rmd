---
title: "Assigment - Naive Bayes DIY"
author:
  - name author here - JuniorB2
  - name reviewer here - TICE97
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
   html_notebook:
    toc: true
    toc_depth: 2
---



```{r}
library(tidyverse)
library(tm)
library(caret)
library(wordcloud)
library(e1071)
```


Choose a suitable dataset from [this](https://github.com/HAN-M3DM-Data-Mining/assignments/tree/master/datasets) folder and train your own Naive Bayes model. Follow all the steps from the CRISP-DM model.


## Business Understanding
I chose the fakenews assignment. The dataframe is more workable than the hate speech file, in this dataframe every article is labeled with 1: unreliable and 0: reliable. 
With the hate speech it has a hate speech index but the posts with no hatespeech are labeled with "NA" and i thought that was more difficult.

## Data Understanding


```{r}
#we download the csv file
rawDF <- read.csv("https://raw.githubusercontent.com/HAN-M3DM-Data-Mining/data-mining-s2y2122-JuniorB2/master/datasets/NB-fakenews.csv", header = TRUE)
head(rawDF)
```


```{r}
rawDF$label <- rawDF$label %>% factor %>% relevel("1")
head(rawDF, 10)
class(rawDF$label)
table(rawDF$label)
#we make the label column a factor here
```


```{r}
s <- sample(c(1:dim(rawDF)[1], 5000))
unreliable <- rawDF[s,] %>% filter(label == "1")
reliable <- rawDF[s,] %>% filter(label == "0")

```

```{r}
wordcloud(unreliable$text, max.words = 20, scale = c(4, 0.8), colors= c("indianred1","indianred2","indianred3","indianred"))
wordcloud(reliable$text, max.words = 20, scale = c(4, 0.8), colors= c("lightsteelblue1","lightsteelblue2","lightsteelblue3","lightsteelblue"))

#unreliable- words: trump - clinton - will - people - hillary - said - the
#reliable- words: The - Said - president - years - trump - people - new - time
```



## Data Preparation
```{r}
rawCorpus <- Corpus(VectorSource(rawDF$text))
inspect(rawCorpus[1:3])
#the raw corpus
```

```{r}
cleancorpus <- rawCorpus %>% tm_map(tolower) %>% tm_map(removeNumbers) 

cleancorpus <- cleancorpus %>% tm_map(tolower) %>% tm_map(removeWords, stopwords()) %>% tm_map(removePunctuation)

cleancorpus <- cleancorpus %>% tm_map(stripWhitespace)
cleanDTM <- cleancorpus %>% DocumentTermMatrix()
inspect(cleanDTM)

freqWords <- cleanDTM %>% findFreqTerms(1000)
cleanDTM2 <- DocumentTermMatrix(cleancorpus, list(dictionary = freqWords))
inspect(cleanDTM2)
#here we clean the raw corpus and wipe all the punctuation and more
#it also creates Document term matrix (DTM) that counts all the words, that is why it takes so long
```



```{r}
set.seed(1234)
trainIndex <- createDataPartition(rawDF$label, p=.75, list = FALSE, times = 1)
head(trainIndex)

trainDF <- rawDF[trainIndex, ]
testDF <- rawDF[-trainIndex, ]

trainCorpus <- cleancorpus[trainIndex]
testCorpus <- cleancorpus[-trainIndex]
trainDTM <- cleanDTM2[trainIndex, ]
testDTM <- cleanDTM2[-trainIndex, ]
#here we prepare the data sets and split them in to 75/25% and tell the all the sets what data they should use
```



```{r}
convert_counts <- function(x) {
  x <- ifelse(x > 0, 1, 0) %>% factor(levels = c(0,1), labels = c("no", "yes"))
}

nColsDTM <- dim(trainDTM)[2]
trainDTM <- apply(trainDTM, MARGIN = 2, convert_counts)
testDTM <- apply(testDTM, MARGIN = 2, convert_counts)

head(trainDTM[,1:10])
#This creates a matrix with every word and the rows are the messages.
# if a word is in the message it will say "yes"
```

# modeling
```{r}
nbayesModel <-  naiveBayes(trainDTM, trainDF$label, laplace = 1)
predVec <- predict(nbayesModel, testDTM)
confusionMatrix(predVec, testDF$label, positive = "1", dnn = c("Prediction", "True"))
#this is the final step of modeling and looking at the outcome
```



## Evaluation and Deployment
text and code here

reviewer adds suggestions for improving the model





